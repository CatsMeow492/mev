package processing

import (
	"context"
	"fmt"
	"math/big"
	"math/rand"
	"sort"
	"sync"
	"testing"
	"time"

	"github.com/ethereum/go-ethereum/common"
	"github.com/mev-engine/l2-mev-strategy-engine/pkg/interfaces"
	"github.com/mev-engine/l2-mev-strategy-engine/pkg/types"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// Performance test constants
const (
	TargetTPS         = 1000
	MaxAverageLatency = 100 * time.Millisecond
	MaxP95Latency     = 200 * time.Millisecond
	TestDuration      = 30 * time.Second
	WarmupDuration    = 5 * time.Second
)

// MockForPerformanceTest implements interfaces for performance testing
type MockForPerformanceTest struct {
	mu           sync.RWMutex
	latencies    []time.Duration
	successCount int64
	failureCount int64
}

func (m *MockForPerformanceTest) GetID() string {
	return "mock-fork-perf"
}

func (m *MockForPerformanceTest) ExecuteTransaction(ctx context.Context, tx *types.Transaction) (*interfaces.SimulationResult, error) {
	start := time.Now()

	// Simulate realistic processing time
	time.Sleep(time.Duration(10+rand.Intn(40)) * time.Millisecond)

	latency := time.Since(start)
	m.mu.Lock()
	m.latencies = append(m.latencies, latency)
	m.successCount++
	m.mu.Unlock()

	return &interfaces.SimulationResult{
		Success:       true,
		GasUsed:       21000,
		GasPrice:      big.NewInt(20000000000),
		ExecutionTime: latency,
	}, nil
}

func (m *MockForPerformanceTest) GetBlockNumber() (*big.Int, error) {
	return big.NewInt(1000000), nil
}

func (m *MockForPerformanceTest) GetBalance(address common.Address) (*big.Int, error) {
	return big.NewInt(1000000000000000000), nil
}

func (m *MockForPerformanceTest) Reset() error {
	return nil
}

func (m *MockForPerformanceTest) Close() error {
	return nil
}

func (m *MockForPerformanceTest) IsHealthy() bool {
	return true
}

func (m *MockForPerformanceTest) GetStats() (int64, int64, []time.Duration) {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.successCount, m.failureCount, append([]time.Duration{}, m.latencies...)
}

// TestWorkerPoolPerformance tests worker pool performance under high load
func TestWorkerPoolPerformance(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping performance test in short mode")
	}

	config := &WorkerPoolConfig{
		PoolSize:        50,
		QueueSize:       10000,
		MaxJobTimeout:   5 * time.Second,
		ShutdownTimeout: 10 * time.Second,
		EnableMetrics:   true,
	}

	pool := NewWorkerPool(config)
	ctx := context.Background()

	err := pool.Start(ctx)
	require.NoError(t, err)
	defer pool.Stop(ctx)

	// Test parameters
	totalJobs := 10000
	concurrency := 100

	var wg sync.WaitGroup
	startTime := time.Now()
	jobLatencies := make([]time.Duration, totalJobs)
	var latencyMutex sync.Mutex

	// Submit jobs concurrently
	for i := 0; i < totalJobs; i++ {
		wg.Add(1)
		go func(jobID int) {
			defer wg.Done()

			jobStart := time.Now()
			job := &TestJob{
				ID:       fmt.Sprintf("perf-job-%d", jobID),
				Duration: time.Duration(10+rand.Intn(40)) * time.Millisecond,
				Priority: rand.Intn(100),
			}

			err := pool.Submit(job)
			if err != nil {
				t.Errorf("Failed to submit job %d: %v", jobID, err)
				return
			}

			// Wait for job completion (simplified for testing)
			jobLatency := time.Since(jobStart)
			latencyMutex.Lock()
			jobLatencies[jobID] = jobLatency
			latencyMutex.Unlock()
		}(i)

		// Control concurrency
		if i%concurrency == 0 {
			time.Sleep(time.Millisecond)
		}
	}

	wg.Wait()
	totalTime := time.Since(startTime)

	// Calculate metrics
	actualTPS := float64(totalJobs) / totalTime.Seconds()

	// Calculate latency percentiles
	validLatencies := make([]time.Duration, 0, totalJobs)
	for _, lat := range jobLatencies {
		if lat > 0 {
			validLatencies = append(validLatencies, lat)
		}
	}

	if len(validLatencies) > 0 {
		avgLatency := calculateAverageLatency(validLatencies)
		p95Latency := calculatePercentileLatency(validLatencies, 0.95)

		// Assertions
		assert.Greater(t, actualTPS, float64(TargetTPS*0.8), "TPS should be at least 80%% of target")
		assert.Less(t, avgLatency, MaxAverageLatency*2, "Average latency should be reasonable")
		assert.Less(t, p95Latency, MaxP95Latency*2, "P95 latency should be reasonable")

		t.Logf("Performance Results:")
		t.Logf("  Total Jobs: %d", totalJobs)
		t.Logf("  Total Time: %v", totalTime)
		t.Logf("  Actual TPS: %.2f", actualTPS)
		t.Logf("  Average Latency: %v", avgLatency)
		t.Logf("  P95 Latency: %v", p95Latency)
	}

	// Check pool stats
	stats := pool.GetStats()
	assert.Greater(t, stats.CompletedJobs, int64(float64(totalJobs)*0.9), "Most jobs should complete successfully")
	assert.Greater(t, stats.Utilization, 0.5, "Pool utilization should be reasonable")
}

// TestTransactionProcessorThroughput tests transaction processor throughput
func TestTransactionProcessorThroughput(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping throughput test in short mode")
	}

	// Create mock dependencies
	mockForkManager := &MockForkManager{}
	mockStrategyEngine := &MockStrategyEngine{}
	mockProfitCalculator := &MockProfitCalculator{}

	config := &TransactionProcessorConfig{
		SimulationPoolSize:    30,
		StrategyPoolSize:      20,
		MaxConcurrentJobs:     200,
		ProcessingTimeout:     2 * time.Second,
		BatchSize:             100,
		PriorityQueueSize:     2000,
		EnableLatencyTracking: true,
		MetricsInterval:       1 * time.Second,
	}

	processor := NewTransactionProcessor(config, mockForkManager, mockStrategyEngine, mockProfitCalculator)
	ctx := context.Background()

	err := processor.Start(ctx)
	require.NoError(t, err)
	defer processor.Stop(ctx)

	// Generate test transactions
	numTransactions := 5000
	transactions := generateTestTransactions(numTransactions)

	// Measure batch processing performance
	startTime := time.Now()

	// Process in batches to simulate realistic load
	batchSize := 100
	var allResults []*interfaces.ProcessingResult

	for i := 0; i < len(transactions); i += batchSize {
		end := i + batchSize
		if end > len(transactions) {
			end = len(transactions)
		}

		batch := transactions[i:end]
		results, err := processor.ProcessBatch(ctx, batch)
		require.NoError(t, err)

		allResults = append(allResults, results...)
	}

	totalTime := time.Since(startTime)
	actualTPS := float64(len(allResults)) / totalTime.Seconds()

	// Verify results
	assert.Equal(t, numTransactions, len(allResults), "All transactions should be processed")
	assert.Greater(t, actualTPS, float64(TargetTPS*0.6), "TPS should meet minimum threshold")

	// Check processing stats
	stats := processor.GetStats()
	assert.Greater(t, stats.SuccessfulProcessed, int64(float64(numTransactions)*0.9), "Most transactions should succeed")
	assert.Less(t, stats.AverageLatency, MaxAverageLatency*3, "Average processing latency should be reasonable")

	t.Logf("Transaction Processor Performance:")
	t.Logf("  Transactions: %d", numTransactions)
	t.Logf("  Total Time: %v", totalTime)
	t.Logf("  Actual TPS: %.2f", actualTPS)
	t.Logf("  Success Rate: %.2f%%", float64(stats.SuccessfulProcessed)/float64(numTransactions)*100)
	t.Logf("  Average Latency: %v", stats.AverageLatency)
}

// TestConcurrentStrategyProcessorPerformance tests concurrent strategy processing
func TestConcurrentStrategyProcessorPerformance(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping strategy performance test in short mode")
	}

	mockLatencyMonitor := NewLatencyMonitor()

	config := DefaultConcurrentStrategyConfig()
	config.WorkerPoolSize = 25

	// Create mock detectors for this test
	mockSandwich := &MockSandwichDetector{}
	mockBackrun := &MockBackrunDetector{}
	mockFrontrun := &MockFrontrunDetector{}
	mockTimeBandit := &MockTimeBanditDetector{}

	processor := NewConcurrentStrategyProcessor(
		config,
		mockSandwich,
		mockBackrun,
		mockFrontrun,
		mockTimeBandit,
		mockLatencyMonitor,
	)

	ctx := context.Background()
	err := processor.Start(ctx)
	require.NoError(t, err)
	defer processor.Stop(ctx)

	// Generate test data
	numTransactions := 2000
	transactions := generateTestTransactions(numTransactions)
	simResults := generateTestSimulationResults(numTransactions)

	// Measure concurrent strategy detection performance
	startTime := time.Now()
	opportunities, err := processor.ProcessOpportunities(ctx, transactions, simResults)
	totalTime := time.Since(startTime)

	require.NoError(t, err)
	actualTPS := float64(numTransactions) / totalTime.Seconds()

	// Verify results
	assert.Greater(t, len(opportunities), 0, "Should detect some opportunities")
	assert.Greater(t, actualTPS, float64(TargetTPS*0.4), "Strategy TPS should meet minimum threshold")

	t.Logf("Concurrent Strategy Performance:")
	t.Logf("  Transactions: %d", numTransactions)
	t.Logf("  Opportunities: %d", len(opportunities))
	t.Logf("  Total Time: %v", totalTime)
	t.Logf("  Actual TPS: %.2f", actualTPS)

	// Check latency metrics
	metrics := mockLatencyMonitor.GetMetrics()
	if metrics.SampleCount > 0 {
		assert.Less(t, metrics.AverageLatency, MaxAverageLatency*2, "Average strategy latency should be reasonable")
		t.Logf("  Average Strategy Latency: %v", metrics.AverageLatency)
		t.Logf("  P95 Strategy Latency: %v", metrics.P95Latency)
	}
}

// BenchmarkWorkerPoolSubmission benchmarks worker pool job submission
func BenchmarkWorkerPoolSubmission(b *testing.B) {
	config := DefaultWorkerPoolConfig()
	config.PoolSize = 20
	config.QueueSize = 10000

	pool := NewWorkerPool(config)
	ctx := context.Background()

	err := pool.Start(ctx)
	require.NoError(b, err)
	defer pool.Stop(ctx)

	b.ResetTimer()
	b.RunParallel(func(pb *testing.PB) {
		i := 0
		for pb.Next() {
			job := &TestJob{
				ID:       fmt.Sprintf("bench-job-%d", i),
				Duration: 10 * time.Millisecond,
				Priority: i % 100,
			}

			err := pool.Submit(job)
			if err != nil {
				b.Errorf("Failed to submit job: %v", err)
			}
			i++
		}
	})
}

// BenchmarkLatencyMonitorRecording benchmarks latency recording
func BenchmarkLatencyMonitorRecording(b *testing.B) {
	monitor := NewLatencyMonitor()

	b.ResetTimer()
	b.RunParallel(func(pb *testing.PB) {
		operation := "test_operation"
		for pb.Next() {
			duration := time.Duration(rand.Intn(100)) * time.Millisecond
			monitor.RecordLatency(operation, duration)
		}
	})
}

// Helper functions

func calculateAverageLatency(latencies []time.Duration) time.Duration {
	if len(latencies) == 0 {
		return 0
	}

	var total time.Duration
	for _, lat := range latencies {
		total += lat
	}
	return total / time.Duration(len(latencies))
}

func calculatePercentileLatency(latencies []time.Duration, percentile float64) time.Duration {
	if len(latencies) == 0 {
		return 0
	}

	// Sort latencies
	sorted := make([]time.Duration, len(latencies))
	copy(sorted, latencies)
	sort.Slice(sorted, func(i, j int) bool {
		return sorted[i] < sorted[j]
	})

	index := int(float64(len(sorted)) * percentile)
	if index >= len(sorted) {
		index = len(sorted) - 1
	}

	return sorted[index]
}

func generateTestTransactions(count int) []*types.Transaction {
	transactions := make([]*types.Transaction, count)

	for i := 0; i < count; i++ {
		toAddr := common.HexToAddress(fmt.Sprintf("0x%040x", i))
		transactions[i] = &types.Transaction{
			Hash:     fmt.Sprintf("0x%064x", i),
			From:     common.HexToAddress("0x1234567890123456789012345678901234567890"),
			To:       &toAddr,
			Value:    big.NewInt(int64(i * 1000000)),
			GasPrice: big.NewInt(int64(20000000000 + i*1000000)),
			GasLimit: 21000,
			Nonce:    uint64(i),
			Data:     []byte{},
		}
	}

	return transactions
}

func generateTestSimulationResults(count int) []*interfaces.SimulationResult {
	results := make([]*interfaces.SimulationResult, count)

	for i := 0; i < count; i++ {
		results[i] = &interfaces.SimulationResult{
			Success:       true,
			GasUsed:       21000,
			GasPrice:      big.NewInt(20000000000),
			ExecutionTime: time.Duration(10+rand.Intn(90)) * time.Millisecond,
		}
	}

	return results
}

// Test job implementation for performance testing
type TestJob struct {
	ID       string
	Duration time.Duration
	Priority int
	executed bool
	mu       sync.Mutex
}

func (j *TestJob) Execute(ctx context.Context) (interface{}, error) {
	j.mu.Lock()
	defer j.mu.Unlock()

	if j.executed {
		return nil, fmt.Errorf("job already executed")
	}

	// Simulate work
	time.Sleep(j.Duration)
	j.executed = true

	return fmt.Sprintf("job-%s-completed", j.ID), nil
}

func (j *TestJob) GetPriority() int {
	return j.Priority
}

func (j *TestJob) GetID() string {
	return j.ID
}

func (j *TestJob) GetTimeout() time.Duration {
	return 5 * time.Second
}
